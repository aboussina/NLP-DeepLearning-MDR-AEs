#######################################################################
#  Title:   train_mdr_model.py
#
#  Purpose: Extract all Medical Device Reports (MDRs) from the openFDA
#           website for use in downstream processing.
#
#  Author:  Aaron Boussina, Hedral Inc.
#
#  Inputs:  openFDA Website
#
#  Output:  An hdf5 dataset (ae_data.h5) output to the current directory
#           containing all available Medical Device Adverse Events,
#           the reported date,the device type, whether the event was
#           an Adverse Event, and the MDR text.
#
#  Revision History:
#  AB 14NOV2020:  N/A, Initial Release.
#######################################################################


#######################################################################
# Import Packages and Source Data
#######################################################################

import os
import pandas as pd
from preprocess_mdr_text import *
from tensorflow.keras.preprocessing.text import Tokenizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.sequence import pad_sequences
import subprocess
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Embedding, LSTM, GlobalAveragePooling1D, Dense, Flatten
from tensorflow.keras.optimizers import Adam

# Set Input Locations
ae_data_loc = "SourceData/aeData.h5"

# Import Data Generated by getMdrSourceData.py
ae_data = pd.read_hdf(ae_data_loc).sample(50000)

#######################################################################
# Text Preprocessing
#######################################################################

# Add device generic name to the MDR text to enable the model to train
# on this information
ae_data['text'] = ae_data['device_type'] + ' ' + ae_data['text']

# Call text processing function to perform text cleanup
preprocess_mdr_text(ae_data)


#######################################################################
# Prepare Embedding Layer
#######################################################################

# Change aeYN for binary classification
ae_data['y'] = 1*(ae_data['aeYN'] == 'Y')

# Break into Training (80%) and Test (20%) sets
X_train, X_test, y_train, y_test = train_test_split(
    ae_data['X'], ae_data['y'], test_size=0.20, random_state=5
)

# Tokenize processed Text
mdr_token = Tokenizer()
mdr_token.fit_on_texts(X_train)

X_train = mdr_token.texts_to_sequences(X_train)
X_test = mdr_token.texts_to_sequences(X_test)

# Pad the sequences
X_train = pad_sequences(X_train, padding='post')
X_test = pad_sequences(X_test, maxlen=len(X_train[0]), padding='post')


#######################################################################
# Create NN Model
#######################################################################

model = Sequential([
  Embedding(
      len(mdr_token.word_index) + 1,
      300,
      name="embeddingLayer",
      input_length=len(X_train[0])
    ),
  Flatten(),
  Dense(300, activation="relu"),
  Dense(300, activation="relu"),
  Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


#######################################################################
# Train NN Model
#######################################################################

model_log = model.fit(
    X_train,
    y_train,
    validation_data=(X_test, y_test),
    batch_size=100,
    epochs=5,
    verbose=1
)

model_score = model.evaluate(X_test, y_test, verbose=1)


#######################################################################
# Output Model Structure and Weights
#######################################################################

model.save_weights("ModelOutputs/MdrModelWeights.h5")

model_structure_output = open('ModelOutputs/MdrModelStructure.json', 'w')
model_structure_output.write(model.to_json())
model_structure_output.close()

mdr_token_output = open('ModelOutputs/mdrToken.json', 'w')
mdr_token_output.write(mdr_token.to_json())
mdr_token_output.close()
